#
<div align="center">
  <a href="https://github.com/nev8rz/vermind">
    <img src="https://raw.githubusercontent.com/nev8rz/vermind/main/docs/assets/vermind_logo.png" alt="VerMind Logo" width="120">
  </a>
  <h1 align="center">VerMind</h1>
  <p align="center">
    A high-performance, lightweight, and modern language model built from the ground up in PyTorch.
    <br />
    <a href="https://nev8rz.github.io/vermind/"><strong>View Demo Â»</strong></a>
    Â·
    <a href="https://github.com/nev8rz/vermind/issues">Report Bug</a>
    Â·
    <a href="https://github.com/nev8rz/vermind/issues">Request Feature</a>
  </p>
</div>

<div align="center">

[![Python 3.12+](https://img.shields.io/badge/Python-3.12+-blue.svg?style=for-the-badge&logo=python)](https://www.python.org/)
[![PyTorch 2.8.0+](https://img.shields.io/badge/PyTorch-2.8.0+-ee4c2c.svg?style=for-the-badge&logo=pytorch)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](https://opensource.org/licenses/MIT)
[![GitHub Stars](https://img.shields.io/github/stars/nev8rz/vermind?style=for-the-badge&logo=github)](https://github.com/nev8rz/vermind/stargazers)

</div>

---

**VerMind** is a comprehensive, end-to-end toolkit for building, training, and deploying custom language models. It features a state-of-the-art architecture, including **Grouped Query Attention (GQA)** and **SwiGLU**, designed for efficient training, fine-tuning, and high-throughput inference. This project is highly modular, extensively documented, and easy to customize, making it an ideal starting point for both research and production.

## âœ¨ Why VerMind?

-   ğŸš€ **Performance & Efficiency**: Implements GQA and Flash Attention to reduce memory footprint and accelerate both training and inference.
-   ğŸ§  **Modern Architecture**: Incorporates the latest advancements in LLM architecture, such as SwiGLU activation and Rotary Position Embedding (RoPE) with YaRN scaling.
-   ğŸ”§ **End-to-End Solution**: Provides a complete workflow from tokenizer training and pre-training to supervised fine-tuning (SFT), LoRA, and deployment with a vLLM adapter.
-   ğŸ§© **Extensibility & Customization**: The modular design makes it easy to experiment with new ideas, swap components, and adapt the model to specific needs.
-   ğŸ“ **Educational Value**: Serves as an excellent learning resource for understanding the inner workings of modern language models, with detailed code and documentation.

## ğŸ› ï¸ Key Features

| Feature                               | Description                                                                                                                            |
| ------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------- |
| âš¡ **Grouped Query Attention (GQA)**  | Reduces the memory bandwidth required for inference by sharing key-value heads, leading to significant speedups.                       |
| ğŸ”¥ **SwiGLU Activation**              | A modern activation function that often leads to better performance compared to traditional ReLU or GeLU.                                |
| ğŸ“ **Rotary Position Embedding (RoPE)** | A relative position encoding scheme that has become standard in high-performance LLMs. Includes YaRN scaling for extending context length. |
| ğŸš€ **vLLM Adapter**                   | Enables blazing-fast inference speeds and an OpenAI-compatible API server out-of-the-box.                                                |
| ğŸ¨ **LoRA Fine-Tuning**               | Supports parameter-efficient fine-tuning (PEFT) with Low-Rank Adaptation for rapid and memory-efficient customization.                 |
| ğŸŒ **Distributed Training**           | Built-in support for Distributed Data Parallel (DDP) to scale training across multiple GPUs.                                             |

## ğŸ—ï¸ Architecture Overview

VerMind's architecture is a decoder-only transformer optimized for performance and scalability. The core components are designed to be both efficient and easy to understand.

```
Input â”¬â”€> RMSNorm â”¬â”€> Grouped Query Attention â”¬â”€> Add & Norm â”¬â”€> SwiGLU FFN â”¬â”€> Output
      |           | (GQA)                     |              |            |
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€|â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â””â”€> Rotary Positional Embedding (RoPE)
```

-   **RMSNorm**: Used for layer normalization, providing better stability.
-   **Rotary Position Embedding (RoPE)**: Applied to queries and keys to inject positional information.
-   **Grouped Query Attention (GQA)**: The attention block where multiple query heads attend to a single key-value head.
-   **SwiGLU Feed-Forward Network**: The FFN block uses the SwiGLU activation for better performance.

## ğŸš€ Getting Started

Get your local copy up and running in a few simple steps.

### Prerequisites

-   Python 3.12+
-   PyTorch 2.8.0+
-   `uv` package manager (recommended)

### Installation

1.  **Clone the repository**
    ```sh
    git clone https://github.com/nev8rz/vermind.git
    cd vermind
    ```
2.  **Create and activate virtual environment**
    ```sh
    uv venv
    source .venv/bin/activate
    ```
3.  **Install dependencies**
    ```sh
    uv pip install -e .
    ```

## ğŸƒâ€â™€ï¸ Usage Examples

### 1. LoRA Fine-Tuning

LoRA is the most efficient way to adapt VerMind to your data.

```python
# train/lora.py
python train/lora.py \
    --data_path /path/to/your_sft_data.jsonl \
    --save_dir ./output/lora \
    --tokenizer_path /path/to/base_model_tokenizer \
    --from_weight /path/to/base_model_checkpoint \
    --lora_rank 16
```

### 2. Deployment with vLLM

Start a high-performance API server compatible with OpenAI's client.

```bash
python vllm_adapter/start_server.py /path/to/your_finetuned_checkpoint

# The server is now running at http://localhost:8000
```

### 3. Making API Requests

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="dummy",
)

response = client.chat.completions.create(
    model="/path/to/your_finetuned_checkpoint",
    messages=[
        {"role": "user", "content": "Explain the importance of Grouped Query Attention."}
    ],
)
print(response.choices[0].message.content)
```

## ğŸ“ Project Structure

```
vermind/
â”œâ”€â”€ vermind_models/          # Core model implementation (GQA, FFN, RoPE)
â”œâ”€â”€ train/                   # Training scripts (pre-train, SFT, LoRA)
â”œâ”€â”€ data_loader/             # Data loading and processing modules
â”œâ”€â”€ scripts/                 # Utility scripts (evaluation, merging LoRA)
â”œâ”€â”€ vllm_adapter/            # Adapter for high-performance vLLM inference
â”œâ”€â”€ docs/                    # GitHub Pages website and assets
â””â”€â”€ pyproject.toml           # Project configuration and dependencies
```

## ğŸ¤ Contributing

Contributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you make are **greatly appreciated**.

1.  Fork the Project
2.  Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3.  Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4.  Push to the Branch (`git push origin feature/AmazingFeature`)
5.  Open a Pull Request

## ğŸ“œ License

Distributed under the MIT License. See `LICENSE` for more information.

## âœ’ï¸ Citation

If you use VerMind in your research or work, please consider citing it:

```bibtex
@software{vermind2026,
  title={VerMind: A High-Performance, Lightweight Language Model with GQA},
  author={Yijin Zhou},
  year={2026},
  url={https://github.com/nev8rz/vermind}
}
```

---

<p align="center">Made with â¤ï¸ by Yijin Zhou</p>
