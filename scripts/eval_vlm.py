#!/usr/bin/env python3
"""
VerMind-V è§†è§‰è¯­è¨€æ¨¡å‹æ¨ç†ä¸å¯¹è¯è„šæœ¬
æ”¯æŒå›¾åƒè¾“å…¥å’Œäº¤äº’å¼å¯¹è¯
"""

import os
import sys
import time
import argparse
import warnings
from pathlib import Path

import torch
from PIL import Image
from transformers import AutoTokenizer

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
from vermind_models import VerMindVLM, VLMConfig

warnings.filterwarnings('ignore')


def load_model(model_path, device='cuda'):
    """åŠ è½½ VerMind-V æ¨¡å‹"""
    print(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {model_path}")
    
    tokenizer = AutoTokenizer.from_pretrained(
        model_path,
        trust_remote_code=True,
        local_files_only=True
    )
    
    model = VerMindVLM.from_pretrained(
        model_path,
        trust_remote_code=True,
        local_files_only=True
    )
    model = model.to(device).eval()
    
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œè®¾å¤‡: {device}\n")
    return model, tokenizer


def generate_response(model, tokenizer, image, prompt, max_length=512, temperature=0.7, device='cuda'):
    """ç”Ÿæˆå›å¤"""
    # æ„å»ºæ¶ˆæ¯
    messages = [
        {"role": "user", "content": f"<image>\n{prompt}"}
    ]
    
    # åº”ç”¨ chat template
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True
    )
    
    # ç¼–ç è¾“å…¥
    inputs = tokenizer(text, return_tensors="pt")
    input_ids = inputs.input_ids.to(device)
    
    # å¤„ç†å›¾åƒ
    pixel_values = VerMindVLM.image2tensor(image, model.processor)
    pixel_values = pixel_values.unsqueeze(0).to(device)
    
    # ç”Ÿæˆ
    with torch.no_grad():
        output = model.generate(
            input_ids=input_ids,
            pixel_values=pixel_values,
            max_new_tokens=max_length,
            temperature=temperature,
            do_sample=True,
            top_p=0.85,
            pad_token_id=tokenizer.pad_token_id,
            eos_token_id=tokenizer.eos_token_id
        )
    
    # è§£ç è¾“å‡º
    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)
    
    # æå–åŠ©æ‰‹å›å¤ï¼ˆå»æ‰è¾“å…¥éƒ¨åˆ†ï¼‰
    # æ‰¾åˆ° assistant æ ‡è®°åçš„å†…å®¹
    if "assistant" in generated_text.lower():
        # å°è¯•æå– assistant éƒ¨åˆ†
        parts = generated_text.split("assistant")
        if len(parts) > 1:
            response = parts[-1].strip()
        else:
            response = generated_text[len(text):].strip()
    else:
        response = generated_text[len(text):].strip()
    
    return response


def list_images(image_dir):
    """åˆ—å‡ºè¯„ä¼°å›¾åƒç›®å½•ä¸­çš„æ‰€æœ‰å›¾ç‰‡"""
    image_dir = Path(image_dir)
    if not image_dir.exists():
        print(f"âŒ å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {image_dir}")
        return []
    
    image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'}
    images = []
    
    for f in sorted(image_dir.iterdir()):
        if f.suffix.lower() in image_extensions:
            images.append(f)
    
    return images


def main():
    parser = argparse.ArgumentParser(description="VerMind-V VLM æ¨ç†ä¸å¯¹è¯")
    parser.add_argument(
        '--model_path',
        type=str,
        required=True,
        help="VLM æ¨¡å‹è·¯å¾„"
    )
    parser.add_argument(
        '--image_dir',
        type=str,
        default='./dataset/eval_images',
        help="è¯„ä¼°å›¾ç‰‡ç›®å½•"
    )
    parser.add_argument(
        '--image',
        type=str,
        default=None,
        help="æŒ‡å®šå•å¼ å›¾ç‰‡è·¯å¾„"
    )
    parser.add_argument(
        '--device',
        type=str,
        default='cuda' if torch.cuda.is_available() else 'cpu',
        help="æ¨ç†è®¾å¤‡"
    )
    parser.add_argument(
        '--max_length',
        type=int,
        default=512,
        help="æœ€å¤§ç”Ÿæˆé•¿åº¦"
    )
    parser.add_argument(
        '--temperature',
        type=float,
        default=0.7,
        help="ç”Ÿæˆæ¸©åº¦"
    )
    parser.add_argument(
        '--show_speed',
        default=1,
        type=int,
        choices=[0, 1],
        help="æ˜¾ç¤ºç”Ÿæˆé€Ÿåº¦"
    )
    args = parser.parse_args()
    
    # åŠ è½½æ¨¡å‹
    model, tokenizer = load_model(args.model_path, args.device)
    
    # å‡†å¤‡å›¾ç‰‡åˆ—è¡¨
    if args.image:
        # ä½¿ç”¨æŒ‡å®šçš„å•å¼ å›¾ç‰‡
        images = [Path(args.image)]
    else:
        # ä½¿ç”¨ç›®å½•ä¸­çš„æ‰€æœ‰å›¾ç‰‡
        images = list_images(args.image_dir)
    
    if not images:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡")
        return
    
    print(f"ğŸ–¼ï¸  æ‰¾åˆ° {len(images)} å¼ å›¾ç‰‡\n")
    print("=" * 60)
    
    # æ˜¾ç¤ºå›¾ç‰‡åˆ—è¡¨
    for i, img_path in enumerate(images):
        print(f"[{i}] {img_path.name}")
    print("=" * 60 + "\n")
    
    # äº¤äº’æ¨¡å¼
    while True:
        try:
            # é€‰æ‹©å›¾ç‰‡
            choice = input(f"é€‰æ‹©å›¾ç‰‡ [0-{len(images)-1}] æˆ– 'q' é€€å‡º: ").strip()
            if choice.lower() == 'q':
                break
            
            try:
                img_idx = int(choice)
                if img_idx < 0 or img_idx >= len(images):
                    print(f"âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 0-{len(images)-1}")
                    continue
            except ValueError:
                print("âŒ æ— æ•ˆè¾“å…¥")
                continue
            
            image_path = images[img_idx]
            print(f"\nğŸ“· åŠ è½½å›¾ç‰‡: {image_path.name}")
            
            # åŠ è½½å›¾ç‰‡
            try:
                image = Image.open(image_path).convert('RGB')
            except Exception as e:
                print(f"âŒ æ— æ³•åŠ è½½å›¾ç‰‡: {e}")
                continue
            
            # å¯¹è¯å¾ªç¯
            conversation = []
            print("\nğŸ’¡ æç¤º: è¾“å…¥é—®é¢˜å¼€å§‹å¯¹è¯ï¼Œè¾“å…¥ 'next' åˆ‡æ¢å›¾ç‰‡ï¼Œè¾“å…¥ 'exit' é€€å‡º\n")
            
            while True:
                # è·å–ç”¨æˆ·è¾“å…¥
                prompt = input('ğŸ’¬: ').strip()
                
                if prompt.lower() == 'exit':
                    return
                if prompt.lower() == 'next':
                    break
                if not prompt:
                    continue
                
                # æ·»åŠ é¢„è®¾æµ‹è¯•æç¤º
                if prompt == 'test':
                    test_prompts = [
                        'æè¿°è¿™å¼ å›¾ç‰‡',
                        'è¿™å¼ å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆï¼Ÿ',
                        'è¯·è¯¦ç»†æè¿°å›¾ç‰‡ä¸­çš„å†…å®¹',
                        'è¿™å¼ å›¾ç‰‡çš„ä¸»è¦å…ƒç´ æ˜¯ä»€ä¹ˆï¼Ÿ'
                    ]
                    print(f"\nğŸ“ è‡ªåŠ¨æµ‹è¯• {len(test_prompts)} ä¸ªæç¤º...\n")
                    for i, test_prompt in enumerate(test_prompts):
                        print(f"[{i+1}/{len(test_prompts)}] ğŸ’¬: {test_prompt}")
                        print('ğŸ¤–: ', end='', flush=True)
                        
                        st = time.time()
                        response = generate_response(
                            model, tokenizer, image, test_prompt,
                            args.max_length, args.temperature, args.device
                        )
                        elapsed = time.time() - st
                        
                        print(response)
                        if args.show_speed:
                            print(f'\n[Time]: {elapsed:.2f}s')
                        print("-" * 40 + "\n")
                    continue
                
                # ç”Ÿæˆå›å¤
                print('ğŸ¤–: ', end='', flush=True)
                st = time.time()
                
                try:
                    response = generate_response(
                        model, tokenizer, image, prompt,
                        args.max_length, args.temperature, args.device
                    )
                    print(response)
                    
                    elapsed = time.time() - st
                    if args.show_speed:
                        print(f'\n[Time]: {elapsed:.2f}s')
                    
                    print("\n" + "-" * 60 + "\n")
                    
                except Exception as e:
                    print(f"\nâŒ ç”Ÿæˆé”™è¯¯: {e}")
                    import traceback
                    traceback.print_exc()
        
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§!")
            break
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    main()
