#!/usr/bin/env python3
"""
VerMind-V è§†è§‰è¯­è¨€æ¨¡å‹æ¨ç†è„šæœ¬ (vLLM API ç‰ˆæœ¬)
é€šè¿‡ OpenAI å…¼å®¹æ¥å£è°ƒç”¨ vLLM æœåŠ¡è¿›è¡Œå›¾åƒç†è§£

æ³¨æ„ï¼švLLM å¯¹ VLM çš„å¤šæ¨¡æ€æ”¯æŒæœ‰é™ï¼Œæ­¤è„šæœ¬ä½¿ç”¨ base64 ç¼–ç å›¾åƒ
"""

import os
import sys
import time
import argparse
import warnings
import base64
from pathlib import Path
from io import BytesIO

from openai import OpenAI
from PIL import Image

warnings.filterwarnings('ignore')


def encode_image_to_base64(image_path):
    """å°†å›¾ç‰‡ç¼–ç ä¸º base64"""
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode('utf-8')


def encode_image_to_base64_pil(image):
    """å°† PIL Image ç¼–ç ä¸º base64"""
    buffered = BytesIO()
    image.save(buffered, format="JPEG")
    return base64.b64encode(buffered.getvalue()).decode('utf-8')


def list_images(image_dir):
    """åˆ—å‡ºè¯„ä¼°å›¾åƒç›®å½•ä¸­çš„æ‰€æœ‰å›¾ç‰‡"""
    image_dir = Path(image_dir)
    if not image_dir.exists():
        print(f"âŒ å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {image_dir}")
        return []
    
    image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'}
    images = []
    
    for f in sorted(image_dir.iterdir()):
        if f.suffix.lower() in image_extensions:
            images.append(f)
    
    return images


def generate_response(client, model, image_path, prompt, max_tokens=512, temperature=0.7):
    """é€šè¿‡ API ç”Ÿæˆå›å¤"""
    # å°†å›¾ç‰‡ç¼–ç ä¸º base64
    base64_image = encode_image_to_base64(image_path)
    
    # æ„å»ºæ¶ˆæ¯ï¼ˆOpenAI è§†è§‰æ ¼å¼ï¼‰
    messages = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": prompt},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_image}"
                    }
                }
            ]
        }
    ]
    
    # è°ƒç”¨ API
    response = client.chat.completions.create(
        model=model,
        messages=messages,
        max_tokens=max_tokens,
        temperature=temperature,
        top_p=0.85
    )
    
    return response.choices[0].message.content


def main():
    parser = argparse.ArgumentParser(description="VerMind-V VLM æ¨ç† (vLLM API)")
    parser.add_argument(
        '--api_base',
        default='http://localhost:8000/v1',
        type=str,
        help="OpenAI API åŸºç¡€ URL"
    )
    parser.add_argument(
        '--api_key',
        default='sk-no-key-required',
        type=str,
        help="API Key"
    )
    parser.add_argument(
        '--model',
        default='vermind-v',
        type=str,
        help="æ¨¡å‹åç§°"
    )
    parser.add_argument(
        '--image_dir',
        type=str,
        default='./dataset/eval_images',
        help="è¯„ä¼°å›¾ç‰‡ç›®å½•"
    )
    parser.add_argument(
        '--image',
        type=str,
        default=None,
        help="æŒ‡å®šå•å¼ å›¾ç‰‡è·¯å¾„"
    )
    parser.add_argument(
        '--max_tokens',
        default=512,
        type=int,
        help="æœ€å¤§ç”Ÿæˆé•¿åº¦"
    )
    parser.add_argument(
        '--temperature',
        default=0.7,
        type=float,
        help="ç”Ÿæˆæ¸©åº¦"
    )
    parser.add_argument(
        '--show_speed',
        default=1,
        type=int,
        choices=[0, 1],
        help="æ˜¾ç¤ºç”Ÿæˆé€Ÿåº¦"
    )
    args = parser.parse_args()
    
    # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
    client = OpenAI(
        api_key=args.api_key,
        base_url=args.api_base
    )
    print(f"ğŸ”— è¿æ¥åˆ° API: {args.api_base}")
    print(f"ğŸ“¦ ä½¿ç”¨æ¨¡å‹: {args.model}\n")
    
    # å‡†å¤‡å›¾ç‰‡åˆ—è¡¨
    if args.image:
        images = [Path(args.image)]
    else:
        images = list_images(args.image_dir)
    
    if not images:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡")
        return
    
    print(f"ğŸ–¼ï¸  æ‰¾åˆ° {len(images)} å¼ å›¾ç‰‡\n")
    print("=" * 60)
    
    for i, img_path in enumerate(images):
        print(f"[{i}] {img_path.name}")
    print("=" * 60 + "\n")
    
    # äº¤äº’æ¨¡å¼
    while True:
        try:
            choice = input(f"é€‰æ‹©å›¾ç‰‡ [0-{len(images)-1}] æˆ– 'q' é€€å‡º: ").strip()
            if choice.lower() == 'q':
                break
            
            try:
                img_idx = int(choice)
                if img_idx < 0 or img_idx >= len(images):
                    print(f"âŒ æ— æ•ˆé€‰æ‹©")
                    continue
            except ValueError:
                print("âŒ æ— æ•ˆè¾“å…¥")
                continue
            
            image_path = images[img_idx]
            print(f"\nğŸ“· å›¾ç‰‡: {image_path.name}")
            
            # å¯¹è¯å¾ªç¯
            print("\nğŸ’¡ æç¤º: è¾“å…¥é—®é¢˜å¼€å§‹å¯¹è¯ï¼Œè¾“å…¥ 'next' åˆ‡æ¢å›¾ç‰‡ï¼Œè¾“å…¥ 'exit' é€€å‡º\n")
            
            while True:
                prompt = input('ğŸ’¬: ').strip()
                
                if prompt.lower() == 'exit':
                    return
                if prompt.lower() == 'next':
                    break
                if not prompt:
                    continue
                
                # æ·»åŠ é¢„è®¾æµ‹è¯•
                if prompt == 'test':
                    test_prompts = [
                        'æè¿°è¿™å¼ å›¾ç‰‡',
                        'è¿™å¼ å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆï¼Ÿ',
                        'è¯·è¯¦ç»†æè¿°å›¾ç‰‡ä¸­çš„å†…å®¹',
                        'è¿™å¼ å›¾ç‰‡çš„ä¸»è¦å…ƒç´ æ˜¯ä»€ä¹ˆï¼Ÿ'
                    ]
                    print(f"\nğŸ“ è‡ªåŠ¨æµ‹è¯• {len(test_prompts)} ä¸ªæç¤º...\n")
                    for i, test_prompt in enumerate(test_prompts):
                        print(f"[{i+1}/{len(test_prompts)}] ğŸ’¬: {test_prompt}")
                        print('ğŸ¤–: ', end='', flush=True)
                        
                        try:
                            st = time.time()
                            response = generate_response(
                                client, args.model, image_path, test_prompt,
                                args.max_tokens, args.temperature
                            )
                            elapsed = time.time() - st
                            
                            print(response)
                            if args.show_speed:
                                print(f'\n[Time]: {elapsed:.2f}s')
                        except Exception as e:
                            print(f"âŒ é”™è¯¯: {e}")
                        
                        print("-" * 40 + "\n")
                    continue
                
                # ç”Ÿæˆå›å¤
                print('ğŸ¤–: ', end='', flush=True)
                st = time.time()
                
                try:
                    response = generate_response(
                        client, args.model, image_path, prompt,
                        args.max_tokens, args.temperature
                    )
                    print(response)
                    
                    elapsed = time.time() - st
                    if args.show_speed:
                        print(f'\n[Time]: {elapsed:.2f}s')
                    
                    print("\n" + "-" * 60 + "\n")
                    
                except Exception as e:
                    print(f"\nâŒ ç”Ÿæˆé”™è¯¯: {e}")
                    import traceback
                    traceback.print_exc()
        
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§!")
            break
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")


if __name__ == "__main__":
    main()
