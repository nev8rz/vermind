#!/usr/bin/env python3
"""
Start vLLM server with VerMind model registration.

The VerMind model is automatically registered via vLLM's plugin system
when the package is installed (via entry_points in pyproject.toml).

If the package is not installed, you can manually register by importing:
    from vllm_adapter.plugin import register_vermind_plugin
    register_vermind_plugin()
"""

import sys
import os
import json
import shutil

# Add parent directory to path (for development mode)
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

# Set PYTHONPATH for subprocesses
os.environ["PYTHONPATH"] = f"/root/vermind:{os.environ.get('PYTHONPATH', '')}"


def ensure_model_config_complete(model_path: str):
    """
    ç¡®ä¿æ¨¡å‹æ–‡ä»¶å¤¹çš„é…ç½®å®Œæ•´ï¼š
    1. æ£€æŸ¥ config.json æ˜¯å¦åŒ…å« auto_mapï¼ˆåŒ…å« AutoConfig å’Œ AutoModelForCausalLMï¼‰
    2. æ£€æŸ¥æ˜¯å¦æœ‰ configuration_vermind.py å’Œ modeling_vermind.py
    3. å¦‚æœç¼ºå¤±ï¼Œè‡ªåŠ¨ä» vllm_adapter ç›®å½•å¤åˆ¶
    
    Args:
        model_path: æ¨¡å‹æ–‡ä»¶å¤¹è·¯å¾„
    """
    if not os.path.isdir(model_path):
        print(f"âš ï¸  æ¨¡å‹è·¯å¾„ä¸æ˜¯ç›®å½•: {model_path}")
        return
    
    adapter_dir = os.path.dirname(__file__)
    config_json_path = os.path.join(model_path, "config.json")
    config_py_path = os.path.join(model_path, "configuration_vermind.py")
    modeling_py_path = os.path.join(model_path, "modeling_vermind.py")
    
    source_config_py = os.path.join(adapter_dir, "configuration_vermind.py")
    source_modeling_py = os.path.join(adapter_dir, "modeling_vermind.py")
    
    needs_update = False
    files_copied = []
    
    # 1. æ£€æŸ¥å¹¶æ›´æ–° config.json
    if os.path.exists(config_json_path):
        try:
            with open(config_json_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # æ£€æŸ¥ auto_map æ˜¯å¦å­˜åœ¨ä¸”å®Œæ•´
            required_auto_map = {
                "AutoConfig": "configuration_vermind.VerMindConfig",
                "AutoModelForCausalLM": "modeling_vermind.VerMindForCausalLM"
            }
            
            if "auto_map" not in config:
                print(f"ğŸ“ æ£€æµ‹åˆ° config.json ç¼ºå°‘ auto_mapï¼Œæ­£åœ¨æ·»åŠ ...")
                config["auto_map"] = required_auto_map
                needs_update = True
            else:
                # æ£€æŸ¥æ˜¯å¦å®Œæ•´
                auto_map = config["auto_map"]
                for key, value in required_auto_map.items():
                    if key not in auto_map or auto_map[key] != value:
                        print(f"ğŸ“ æ£€æµ‹åˆ° config.json çš„ auto_map ä¸å®Œæ•´ï¼Œæ­£åœ¨æ›´æ–°...")
                        if "auto_map" not in config:
                            config["auto_map"] = {}
                        config["auto_map"][key] = value
                        needs_update = True
            
            if needs_update:
                # å¤‡ä»½åŸæ–‡ä»¶
                backup_path = config_json_path + ".backup"
                if not os.path.exists(backup_path):
                    shutil.copy2(config_json_path, backup_path)
                    print(f"   ğŸ’¾ å·²å¤‡ä»½åŸ config.json åˆ° {os.path.basename(backup_path)}")
                
                # å†™å…¥æ›´æ–°åçš„é…ç½®
                with open(config_json_path, 'w', encoding='utf-8') as f:
                    json.dump(config, f, indent=2, ensure_ascii=False)
                print(f"   âœ… å·²æ›´æ–° config.json")
        except Exception as e:
            print(f"âš ï¸  è¯»å–/æ›´æ–° config.json æ—¶å‡ºé”™: {e}")
    else:
        print(f"âš ï¸  æœªæ‰¾åˆ° config.json: {config_json_path}")
    
    # 2. æ£€æŸ¥å¹¶å¤åˆ¶ configuration_vermind.py
    if not os.path.exists(config_py_path):
        if os.path.exists(source_config_py):
            try:
                shutil.copy2(source_config_py, config_py_path)
                files_copied.append("configuration_vermind.py")
                print(f"   âœ… å·²å¤åˆ¶ configuration_vermind.py åˆ°æ¨¡å‹æ–‡ä»¶å¤¹")
            except Exception as e:
                print(f"   âŒ å¤åˆ¶ configuration_vermind.py å¤±è´¥: {e}")
        else:
            print(f"   âš ï¸  æºæ–‡ä»¶ä¸å­˜åœ¨: {source_config_py}")
    else:
        print(f"   âœ“ configuration_vermind.py å·²å­˜åœ¨")
    
    # 3. æ£€æŸ¥å¹¶å¤åˆ¶ modeling_vermind.py
    if not os.path.exists(modeling_py_path):
        if os.path.exists(source_modeling_py):
            try:
                shutil.copy2(source_modeling_py, modeling_py_path)
                files_copied.append("modeling_vermind.py")
                print(f"   âœ… å·²å¤åˆ¶ modeling_vermind.py åˆ°æ¨¡å‹æ–‡ä»¶å¤¹")
            except Exception as e:
                print(f"   âŒ å¤åˆ¶ modeling_vermind.py å¤±è´¥: {e}")
        else:
            print(f"   âš ï¸  æºæ–‡ä»¶ä¸å­˜åœ¨: {source_modeling_py}")
    else:
        print(f"   âœ“ modeling_vermind.py å·²å­˜åœ¨")
    
    # æ€»ç»“
    if needs_update or files_copied:
        print(f"   ğŸ“‹ é…ç½®è¡¥å…¨å®Œæˆ: {'å·²æ›´æ–° config.json' if needs_update else ''} {'å·²å¤åˆ¶æ–‡ä»¶: ' + ', '.join(files_copied) if files_copied else ''}")
    else:
        print(f"   âœ“ æ‰€æœ‰é…ç½®æ–‡ä»¶å®Œæ•´ï¼Œæ— éœ€è¡¥å…¨")


# ä»å‘½ä»¤è¡Œå‚æ•°ä¸­æå–æ¨¡å‹è·¯å¾„ï¼ˆåœ¨è®¾ç½® sys.argv ä¹‹å‰ï¼‰
# æ£€æŸ¥æ˜¯å¦æœ‰æ¨¡å‹è·¯å¾„å‚æ•°
model_path = None
original_argv = sys.argv.copy()

if len(original_argv) > 1:
    # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªçœ‹èµ·æ¥åƒè·¯å¾„çš„å‚æ•°ï¼ˆä¸æ˜¯ä»¥ -- å¼€å¤´ï¼‰
    for arg in original_argv[1:]:
        if not arg.startswith('--') and (os.path.exists(arg) or os.path.isdir(arg)):
            model_path = arg
            break

# å¦‚æœä» sys.argv ä¸­æ‰¾åˆ°äº†æ¨¡å‹è·¯å¾„ï¼Œè¿›è¡Œé…ç½®æ£€æŸ¥å’Œè¡¥å…¨
if model_path:
    print(f"ğŸ” æ£€æŸ¥æ¨¡å‹é…ç½®å®Œæ•´æ€§: {model_path}")
    ensure_model_config_complete(model_path)
    print()

# CRITICAL: Register plugin BEFORE importing any vLLM modules
# This ensures the model is registered before vLLM validates architectures
# Also ensure plugin is loaded in subprocesses by setting up the plugin system
try:
    from vllm_adapter.plugin import register_vermind_plugin
    register_vermind_plugin()
    print("âœ… VerMind plugin registered successfully")
except ImportError as e:
    print(f"âš ï¸  Warning: Could not import plugin: {e}")
    # Try to register manually
    try:
        import sys
        sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
        from vllm_adapter.plugin import register_vermind_plugin
        register_vermind_plugin()
        print("âœ… VerMind plugin registered (fallback)")
    except Exception as e2:
        print(f"âŒ Failed to register plugin: {e2}")
        sys.exit(1)

# Verify registration before proceeding
try:
    from vllm import ModelRegistry
    supported = list(ModelRegistry.get_supported_archs())
    if "VerMindForCausalLM" not in supported:
        print(f"âŒ ERROR: VerMindForCausalLM not found in supported architectures!")
        print(f"   Supported: {supported[:10]}...")
        sys.exit(1)
    print(f"âœ… VerMindForCausalLM is registered in ModelRegistry")
except Exception as e:
    print(f"âš ï¸  Warning: Could not verify registration: {e}")

# Ensure plugin is available for subprocesses by monkey-patching vLLM's plugin loader
# This is needed because vLLM loads plugins in subprocesses, and entry_points may not be available
try:
    # Import vLLM's plugin system and ensure our plugin is registered
    import vllm.plugins as vllm_plugins
    # Register our plugin function so it's available when vLLM loads plugins
    if not hasattr(vllm_plugins, '_manual_plugins'):
        vllm_plugins._manual_plugins = {}
    vllm_plugins._manual_plugins['vllm.general_plugins'] = vllm_plugins._manual_plugins.get('vllm.general_plugins', {})
    from vllm_adapter.plugin import register_vermind_plugin
    vllm_plugins._manual_plugins['vllm.general_plugins']['vermind'] = register_vermind_plugin
    
    # Monkey-patch load_plugins_by_group to include our manual plugin
    original_load = getattr(vllm_plugins, 'load_plugins_by_group', None)
    if original_load:
        def patched_load_plugins_by_group(group):
            result = original_load(group) if original_load else {}
            # Add our manual plugin if not already loaded
            if group == 'vllm.general_plugins' and 'vermind' not in result:
                result['vermind'] = register_vermind_plugin
            return result
        vllm_plugins.load_plugins_by_group = patched_load_plugins_by_group
        print("âœ… VerMind plugin patched into vLLM plugin system")
except Exception as e:
    # If patching fails, that's okay - manual registration should still work
    print(f"âš ï¸  Note: Could not patch plugin system (manual registration should work): {e}")

# Now use vLLM's CLI interface
# Set sys.argv to match vLLM's expected arguments
# å¦‚æœä¹‹å‰æ²¡æœ‰ä» sys.argv æå–åˆ°æ¨¡å‹è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤å€¼
if model_path is None:
    model_path = "/root/vermind/output/pretrain/pretrain_768/checkpoint_10000"
    # ä½¿ç”¨é»˜è®¤è·¯å¾„æ—¶ï¼Œä¹Ÿéœ€è¦æ£€æŸ¥é…ç½®
    if os.path.exists(model_path):
        print(f"ğŸ” æ£€æŸ¥æ¨¡å‹é…ç½®å®Œæ•´æ€§: {model_path}")
        ensure_model_config_complete(model_path)
        print()

sys.argv = [
    "vllm",
    "serve",
    model_path,
    "--gpu-memory-utilization", "0.1",
    "--trust-remote-code",
    "--port", "8000",
    "--host", "0.0.0.0",
]

# Import and run vLLM's main entry point
# This import happens AFTER registration
if __name__ == "__main__":
    from vllm.entrypoints.cli.main import main
    main()
